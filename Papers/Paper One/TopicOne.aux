\relax 
\abx@aux@refcontext{none/global//global/global/global}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{Abstract}{2}{Doc-Start}\protected@file@percent }
\abx@aux@cite{0}{SAEJ3016_2021}
\abx@aux@segm{0}{0}{SAEJ3016_2021}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Technology Description}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}SAE Levels of Automation}{3}{subsection.2.1}\protected@file@percent }
\abx@aux@cite{0}{2019Royo}
\abx@aux@segm{0}{0}{2019Royo}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces SAE J3016 Levels of Driving Automation}}{4}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:sae}{{I}{4}{SAE J3016 Levels of Driving Automation}{table.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}LiDAR: Time-of-Flight (ToF) Principles}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Pulsed ToF:}{4}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{eq:tof_pulse}{{1}{4}{Pulsed ToF:}{equation.1}{}}
\abx@aux@cite{0}{2019Royo}
\abx@aux@segm{0}{0}{2019Royo}
\abx@aux@cite{0}{2019Royo}
\abx@aux@segm{0}{0}{2019Royo}
\abx@aux@cite{0}{petermannopto}
\abx@aux@segm{0}{0}{petermannopto}
\abx@aux@cite{0}{2019Royo}
\abx@aux@segm{0}{0}{2019Royo}
\abx@aux@cite{0}{2019Royo}
\abx@aux@segm{0}{0}{2019Royo}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The Pulsed Approach to Determining Object Distance \blx@tocontentsinit {0}\cite {2019Royo}}}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:pulse}{{1}{5}{The Pulsed Approach to Determining Object Distance \cite {2019Royo}}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}AMCW (Amplitude-Modulated Continuous Wave):}{5}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{eq:amcw}{{2}{5}{AMCW (Amplitude-Modulated Continuous Wave):}{equation.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Measuring Distance by Phase Difference \blx@tocontentsinit {0}\cite {2019Royo}}}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:amcw}{{2}{5}{Measuring Distance by Phase Difference \cite {2019Royo}}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}FMCW (Frequency-Modulated Continuous Wave):}{5}{subsubsection.2.2.3}\protected@file@percent }
\newlabel{eq:fmcw}{{3}{5}{FMCW (Frequency-Modulated Continuous Wave):}{equation.3}{}}
\abx@aux@cite{0}{petermannopto}
\abx@aux@segm{0}{0}{petermannopto}
\abx@aux@cite{0}{RT3D}
\abx@aux@segm{0}{0}{RT3D}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Measuring Distance by Frequency Modulation \blx@tocontentsinit {0}\cite {2019Royo}}}{6}{figure.caption.4}\protected@file@percent }
\newlabel{fig:fmcw}{{3}{6}{Measuring Distance by Frequency Modulation \cite {2019Royo}}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Voxelization:}{6}{subsubsection.2.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The combining of the point cloud forms an image where (a) is the interpreted collection of point clouds inferred by the distance calculation in the sensor, (b) is the segmentation of this set of distances into a grid to create a 'set of sets' of different points, (c) is the transformer pipeline which leads to object identification, and (d) is the outcome with identified objects boxed \blx@tocontentsinit {0}\autocite {RT3D}.}}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:voxelization}{{4}{6}{The combining of the point cloud forms an image where (a) is the interpreted collection of point clouds inferred by the distance calculation in the sensor, (b) is the segmentation of this set of distances into a grid to create a 'set of sets' of different points, (c) is the transformer pipeline which leads to object identification, and (d) is the outcome with identified objects boxed \autocite {RT3D}}{figure.caption.5}{}}
\abx@aux@cite{0}{Han2023FourDRadarSurvey}
\abx@aux@segm{0}{0}{Han2023FourDRadarSurvey}
\abx@aux@cite{0}{Rana2023PerceptionSystems}
\abx@aux@segm{0}{0}{Rana2023PerceptionSystems}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Radar: Doppler and Velocity Estimation}{7}{subsection.2.3}\protected@file@percent }
\newlabel{eq:radar_doppler}{{4}{7}{Radar: Doppler and Velocity Estimation}{equation.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The classic Doppler example showing an ambulance emitting sound. An observer, from whom the ambulance leaving from will receive fewer pressure and will hear a deeper note, while an observer from whom the ambulance is approaching will receive higher pressure fluctuations and hear a higher note.}}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig:doppler}{{5}{7}{The classic Doppler example showing an ambulance emitting sound. An observer, from whom the ambulance leaving from will receive fewer pressure and will hear a deeper note, while an observer from whom the ambulance is approaching will receive higher pressure fluctuations and hear a higher note}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Sensor Fusion and Noise Correlation}{7}{subsection.2.4}\protected@file@percent }
\newlabel{eq:noise}{{5}{7}{Sensor Fusion and Noise Correlation}{equation.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Vision-Primary Perception Stack}{7}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}System Architecture:}{7}{subsubsection.2.5.1}\protected@file@percent }
\abx@aux@cite{0}{goff2025learningdriveworldmodel}
\abx@aux@segm{0}{0}{goff2025learningdriveworldmodel}
\abx@aux@cite{0}{Esser2021TamingTransformersHighResolutionImage}
\abx@aux@segm{0}{0}{Esser2021TamingTransformersHighResolutionImage}
\abx@aux@cite{0}{Chen2024EndToEndAD}
\abx@aux@segm{0}{0}{Chen2024EndToEndAD}
\abx@aux@cite{0}{drivingsim}
\abx@aux@segm{0}{0}{drivingsim}
\abx@aux@cite{0}{vaswani2023attentionneed}
\abx@aux@segm{0}{0}{vaswani2023attentionneed}
\abx@aux@cite{0}{vaswani2023attentionneed}
\abx@aux@segm{0}{0}{vaswani2023attentionneed}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Token-Based Image Compression:}{8}{subsubsection.2.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Vision-based pipeline with VQGAN tokenization and transformer rollout \blx@tocontentsinit {0}\autocite {Esser2021TamingTransformersHighResolutionImage}.}}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:tokenizer}{{6}{8}{Vision-based pipeline with VQGAN tokenization and transformer rollout \autocite {Esser2021TamingTransformersHighResolutionImage}}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.3}Autoregressive Planning with Transformers}{8}{subsubsection.2.5.3}\protected@file@percent }
\abx@aux@cite{0}{drivingsim}
\abx@aux@segm{0}{0}{drivingsim}
\abx@aux@cite{0}{goff2025learningdriveworldmodel}
\abx@aux@segm{0}{0}{goff2025learningdriveworldmodel}
\abx@aux@cite{0}{wang2024}
\abx@aux@segm{0}{0}{wang2024}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Transformer model for sequence prediction from visual tokens \blx@tocontentsinit {0}\autocite {vaswani2023attentionneed}.}}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:transformer}{{7}{9}{Transformer model for sequence prediction from visual tokens \autocite {vaswani2023attentionneed}}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The Vision Pipeline shows the original camera image, the feature map, and the image mask \blx@tocontentsinit {0}\cite {wang2024}.}}{9}{figure.caption.9}\protected@file@percent }
\newlabel{fig:visionpipe}{{8}{9}{The Vision Pipeline shows the original camera image, the feature map, and the image mask \cite {wang2024}}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}LiDAR/Radar Fusion-Based Architecture}{9}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}Pipeline Overview:}{9}{subsubsection.2.6.1}\protected@file@percent }
\abx@aux@cite{0}{Haghighi2024}
\abx@aux@segm{0}{0}{Haghighi2024}
\abx@aux@cite{0}{Chen2024EndToEndAD}
\abx@aux@segm{0}{0}{Chen2024EndToEndAD}
\abx@aux@cite{0}{Rana2023PerceptionSystems}
\abx@aux@segm{0}{0}{Rana2023PerceptionSystems}
\abx@aux@cite{0}{Rana2023PerceptionSystems}
\abx@aux@segm{0}{0}{Rana2023PerceptionSystems}
\abx@aux@cite{0}{wang2024}
\abx@aux@segm{0}{0}{wang2024}
\abx@aux@cite{0}{wang2024}
\abx@aux@segm{0}{0}{wang2024}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Reference LiDAR/radar fusion architecture \blx@tocontentsinit {0}\autocite {Haghighi2024}.}}{10}{figure.caption.10}\protected@file@percent }
\newlabel{fig:lidarstack}{{9}{10}{Reference LiDAR/radar fusion architecture \autocite {Haghighi2024}}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2}Fusion Tradeoffs and Challenges:}{10}{subsubsection.2.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Representations of point clouds from LiDAR/Radar are raw point clouds, post voxel-sampling, and the generated the point clouds view in Birds-Eye-View \blx@tocontentsinit {0}\cite {wang2024}.}}{10}{figure.caption.11}\protected@file@percent }
\newlabel{fig:voxels}{{10}{10}{Representations of point clouds from LiDAR/Radar are raw point clouds, post voxel-sampling, and the generated the point clouds view in Birds-Eye-View \cite {wang2024}}{figure.caption.11}{}}
\abx@aux@cite{0}{kitti}
\abx@aux@segm{0}{0}{kitti}
\abx@aux@cite{0}{nuscenes}
\abx@aux@segm{0}{0}{nuscenes}
\abx@aux@cite{0}{goff2025learningdriveworldmodel}
\abx@aux@segm{0}{0}{goff2025learningdriveworldmodel}
\abx@aux@cite{0}{Rana2023PerceptionSystems}
\abx@aux@segm{0}{0}{Rana2023PerceptionSystems}
\abx@aux@cite{0}{wang2024}
\abx@aux@segm{0}{0}{wang2024}
\abx@aux@cite{0}{Li2022BEVFormer}
\abx@aux@segm{0}{0}{Li2022BEVFormer}
\abx@aux@cite{0}{Zhang2023MultiSensorFusionSurvey}
\abx@aux@segm{0}{0}{Zhang2023MultiSensorFusionSurvey}
\abx@aux@cite{0}{Liao2024RadarVisionFusion}
\abx@aux@segm{0}{0}{Liao2024RadarVisionFusion}
\abx@aux@cite{0}{Chen2024EndToEndAD}
\abx@aux@segm{0}{0}{Chen2024EndToEndAD}
\@writefile{toc}{\contentsline {section}{\numberline {3}Comparisons}{11}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Detection Accuracy and Depth Estimation}{11}{subsection.3.1}\protected@file@percent }
\newlabel{eq:recall}{{6}{11}{Detection Accuracy and Depth Estimation}{equation.6}{}}
\newlabel{eq:ap}{{7}{11}{Detection Accuracy and Depth Estimation}{equation.7}{}}
\newlabel{eq:map}{{8}{11}{Detection Accuracy and Depth Estimation}{equation.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Findings}{11}{subsection.3.2}\protected@file@percent }
\abx@aux@cite{0}{Rana2023PerceptionSystems}
\abx@aux@segm{0}{0}{Rana2023PerceptionSystems}
\abx@aux@cite{0}{Han2023FourDRadarSurvey}
\abx@aux@segm{0}{0}{Han2023FourDRadarSurvey}
\abx@aux@cite{0}{2023dreissig}
\abx@aux@segm{0}{0}{2023dreissig}
\abx@aux@cite{0}{Rana2023PerceptionSystems}
\abx@aux@segm{0}{0}{Rana2023PerceptionSystems}
\abx@aux@cite{0}{goff2025learningdriveworldmodel}
\abx@aux@segm{0}{0}{goff2025learningdriveworldmodel}
\abx@aux@cite{0}{Liao2024RadarVisionFusion}
\abx@aux@segm{0}{0}{Liao2024RadarVisionFusion}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Computational Latency and Power Efficiency}{12}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Robustness in Adverse Conditions}{12}{subsection.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces LiDAR scans of a street environment under clear weather conditions (top) and with fog (bottom). The lower image shows significant point cloud degradation and sparsity due to adverse atmospheric interference \blx@tocontentsinit {0}\autocite {2023dreissig}.}}{12}{figure.caption.12}\protected@file@percent }
\newlabel{fig:lidar_noise}{{11}{12}{LiDAR scans of a street environment under clear weather conditions (top) and with fog (bottom). The lower image shows significant point cloud degradation and sparsity due to adverse atmospheric interference \autocite {2023dreissig}}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Noise Propagation and Calibration Drift}{12}{subsection.3.5}\protected@file@percent }
\abx@aux@cite{0}{Shetty2022LiDARvsCamera}
\abx@aux@segm{0}{0}{Shetty2022LiDARvsCamera}
\abx@aux@cite{0}{Sajjad2021ComparativeDetection}
\abx@aux@segm{0}{0}{Sajjad2021ComparativeDetection}
\abx@aux@cite{0}{Haghighi2024}
\abx@aux@segm{0}{0}{Haghighi2024}
\abx@aux@cite{0}{TeslaAutonomyDay2019}
\abx@aux@segm{0}{0}{TeslaAutonomyDay2019}
\abx@aux@cite{0}{Liao2024RadarVisionFusion}
\abx@aux@segm{0}{0}{Liao2024RadarVisionFusion}
\abx@aux@cite{0}{goff2025learningdriveworldmodel}
\abx@aux@segm{0}{0}{goff2025learningdriveworldmodel}
\abx@aux@cite{0}{Hasanujjaman2023}
\abx@aux@segm{0}{0}{Hasanujjaman2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Cost and Complexity of Deployment}{13}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Further Discussions}{13}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Vision as the Core, Radar as the Shield:}{13}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Radar as a Resilient Fallback}{13}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}A Unified Multimodal Framework}{13}{subsection.4.3}\protected@file@percent }
\abx@aux@cite{0}{Zhang2023MultiSensorFusionSurvey}
\abx@aux@segm{0}{0}{Zhang2023MultiSensorFusionSurvey}
\abx@aux@cite{0}{Liao2024RadarVisionFusion}
\abx@aux@segm{0}{0}{Liao2024RadarVisionFusion}
\abx@aux@cite{0}{Chen2024EndToEndAD}
\abx@aux@segm{0}{0}{Chen2024EndToEndAD}
\abx@aux@cite{0}{Rana2023PerceptionSystems}
\abx@aux@segm{0}{0}{Rana2023PerceptionSystems}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Modular architecture integrating vision, radar, and LiDAR inputs \blx@tocontentsinit {0}\autocite {Hasanujjaman2023}.}}{14}{figure.caption.13}\protected@file@percent }
\newlabel{fig:multiarch}{{12}{14}{Modular architecture integrating vision, radar, and LiDAR inputs \autocite {Hasanujjaman2023}}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Summary}{14}{subsection.4.4}\protected@file@percent }
\abx@aux@cite{0}{Rana2023PerceptionSystems}
\abx@aux@segm{0}{0}{Rana2023PerceptionSystems}
\abx@aux@cite{0}{Han2023FourDRadarSurvey}
\abx@aux@segm{0}{0}{Han2023FourDRadarSurvey}
\abx@aux@cite{0}{Shetty2022LiDARvsCamera}
\abx@aux@segm{0}{0}{Shetty2022LiDARvsCamera}
\abx@aux@cite{0}{Sajjad2021ComparativeDetection}
\abx@aux@segm{0}{0}{Sajjad2021ComparativeDetection}
\abx@aux@cite{0}{Hasanujjaman2023}
\abx@aux@segm{0}{0}{Hasanujjaman2023}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces A Multi-Modal Approach to ADS \blx@tocontentsinit {0}\autocite {Hasanujjaman2023}}}{15}{figure.caption.14}\protected@file@percent }
\newlabel{fig:multimodal}{{13}{15}{A Multi-Modal Approach to ADS \autocite {Hasanujjaman2023}}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{15}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{16}{section.5}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{A30719F4642732FA101F61CB32A3DE4E}
\abx@aux@defaultrefcontext{0}{SAEJ3016_2021}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{2019Royo}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{petermannopto}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{RT3D}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Han2023FourDRadarSurvey}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Rana2023PerceptionSystems}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{goff2025learningdriveworldmodel}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Esser2021TamingTransformersHighResolutionImage}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Chen2024EndToEndAD}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{drivingsim}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{vaswani2023attentionneed}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{wang2024}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Haghighi2024}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{kitti}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{nuscenes}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Li2022BEVFormer}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Zhang2023MultiSensorFusionSurvey}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Liao2024RadarVisionFusion}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{2023dreissig}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Shetty2022LiDARvsCamera}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Sajjad2021ComparativeDetection}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{TeslaAutonomyDay2019}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Hasanujjaman2023}{none/global//global/global/global}
\gdef \@abspage@last{18}
